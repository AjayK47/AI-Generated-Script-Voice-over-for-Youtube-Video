{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAQc4x1fL23n"
   },
   "source": [
    "# AI Youtube Video Voice Over and script Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LRqlkWeL8sJ"
   },
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RltRgTWYy5w4",
    "outputId": "43d6554c-3771-411b-a5a3-72a8c2510b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/318.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --q duckduckgo_search google-generativeai soundfile gradio-Client sounddevice langchain-groq langchain-core elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "uISl4-9oEUNR",
    "outputId": "ef2644cc-0d82-4188-93aa-5b2e3b9c8b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libportaudio2\n",
      "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
      "Need to get 65.3 kB of archives.\n",
      "After this operation, 223 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
      "Fetched 65.3 kB in 0s (504 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libportaudio2:amd64.\n",
      "(Reading database ... 123598 files and directories currently installed.)\n",
      "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
      "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIm8qmkZMIpO"
   },
   "source": [
    "### import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAI0ttsA2S8J"
   },
   "outputs": [],
   "source": [
    "# import neccessary libraries\n",
    "import os\n",
    "from groq import Groq\n",
    "from google.colab import userdata\n",
    "from gradio_client import Client\n",
    "from duckduckgo_search import DDGS\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from gradio_client import Client\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play, save, stream, Voice, VoiceSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QilO8NZ6kCj"
   },
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "  \"\"\"Prompts the user for a video title.\"\"\"\n",
    "  title = input(\"Enter the title of your YouTube video: \")\n",
    "  return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfwATL7SEef9"
   },
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joy-RJqJHXIC"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LS3eRMTJZckO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4JUQchTH58X"
   },
   "outputs": [],
   "source": [
    "# Gemini Model\n",
    "def search_and_summarize(search_query):\n",
    "  results = DDGS().text(\n",
    "      keywords=search_query,\n",
    "      region='us-en',\n",
    "      safesearch='off',\n",
    "      timelimit='2m',\n",
    "      max_results=5\n",
    "  )\n",
    "# Extract text content from search results\n",
    "  text_content = [result['body'] for result in results]\n",
    "  gemini =  genai.GenerativeModel('gemini-1.5-flash')\n",
    "  summary = gemini.generate_content(\n",
    "      \"Summarize the following text: \" + \" \".join(text_content),\n",
    "  )\n",
    "  context=summary.text\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrkNJu0cISDf"
   },
   "outputs": [],
   "source": [
    "# Generating youtube script with Gemini\n",
    "prompt='''\n",
    "\n",
    "Generate a YouTube script voiceover based on the following title and context.  Make it sound like a natural conversation, with pauses and a conversational tone.\n",
    "\n",
    "Title: {title}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "The voiceover should start with a strong introduction, followed by key points that highlight the main aspects of the topic, and conclude with a statement that leaves the viewer wanting to learn more.\n",
    "\n",
    "Only provide the voiceover text, without any additional formatting or instructions.\n",
    "'''\n",
    "def generate_youtube_script(title, context):\n",
    "  \"\"\"Generates a YouTube script based on the title and summary.\"\"\"\n",
    "  gemini =  genai.GenerativeModel('gemini-1.5-flash')\n",
    "  script = gemini.generate_content([prompt,title,context]\n",
    "  )\n",
    "  return script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FObed0xNIt7p"
   },
   "outputs": [],
   "source": [
    "# Text to speech from third party host api available at Hugging face using MELLOTTS-ENGLISH Model\n",
    "def text_to_speech(output):\n",
    "    client = Client(\"mrfakename/MeloTTS\")\n",
    "    result = client.predict(\n",
    "        text=output,\n",
    "        speaker=\"EN-US\",\n",
    "        speed=1,\n",
    "        language=\"EN\",\n",
    "        api_name=\"/synthesize\"\n",
    "    )\n",
    "    data, samplerate = sf.read(result)\n",
    "    output_filename = \"output2.wav\"\n",
    "    sf.write(output_filename, data, samplerate)\n",
    "    print(f\"Audio saved to: {output_filename}\")\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "ulaEhfw-KvFx",
    "outputId": "5fd21ff8-6765-4326-aedc-89c8bb157019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the title of your YouTube video: why paris olympics costed so cheap to organise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://mrfakename-melotts.hf.space ✔\n",
      "Audio saved to: output2.wav\n"
     ]
    }
   ],
   "source": [
    "# Main Function\n",
    "def main():\n",
    "  title = get_user_input()\n",
    "  summary = search_and_summarize(title)\n",
    "  script = generate_youtube_script(title, summary)\n",
    "  output=script.text\n",
    "  audio=text_to_speech(output)\n",
    "  return audio\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NkDHNWdJExh"
   },
   "outputs": [],
   "source": [
    "# search and summarize with Groq llm\n",
    "def search_and_summarize(search_query):\n",
    "    # Use DuckDuckGo search to get search results\n",
    "    results = DDGS().text(\n",
    "        keywords=search_query,\n",
    "        region='us-en',\n",
    "        safesearch='off',\n",
    "        timelimit='2m',\n",
    "        max_results=5\n",
    "    )\n",
    "    # Extract text content from search results\n",
    "    text_content = [result['body'] for result in results]\n",
    "    # Initialize Groq client and create a chat completion\n",
    "    client = Groq()\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Summarize the following text: \" + \" \".join(text_content)\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    # Collect the summarized content\n",
    "    summary = \"\"\n",
    "    for chunk in completion:\n",
    "        summary += chunk.choices[0].delta.content or \"\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oCNL0lfr4uuh"
   },
   "outputs": [],
   "source": [
    "# Generate youtube Script with Groq LLM\n",
    "def generate_youtube_script(title, context):\n",
    "    \"\"\"Generates a YouTube script based on the title and summary.\"\"\"\n",
    "    llm = ChatGroq(temperature=0.1, model_name=\"llama-3.1-70b-versatile\")\n",
    "    system = \"You are a skilled scriptwriter for YouTube videos.\"\n",
    "    # Create the prompt using the custom template\n",
    "    prompt_text = f\"\"\"\n",
    "    Generate a YouTube script voiceover for one minute based on the following title and context. Make it sound like a natural conversation, with pauses and a conversational tone .\n",
    "\n",
    "    Title: {title}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    The voiceover should start with a strong introduction, followed by key points that highlight the main aspects of the topic, and conclude with a statement that leaves the viewer wanting to learn more.\n",
    "\n",
    "    Only provide the voiceover text, without any additional formatting or instructions.\n",
    "    \"\"\"\n",
    "    # Create a chat prompt consisting of the system and human messages\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", prompt_text)])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"text\": prompt_text})\n",
    "    script = response.content\n",
    "    return script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNuNTqEv5W17"
   },
   "outputs": [],
   "source": [
    "# Text to Speech Using the ELeven Labs API\n",
    "\n",
    "ELEVEN_LABS_API_KEY = userdata.get('ELEVEN_LABS_API_KEY')\n",
    "client = ElevenLabs(api_key=ELEVEN_LABS_API_KEY)\n",
    "def text_to_speech(output):\n",
    "  audio = client.generate(\n",
    "   text= output,\n",
    "   voice=\"Brian\"\n",
    "  )\n",
    "  return save(audio, \"outpu3.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQcNSw0-5tGe"
   },
   "source": [
    "Disclaimer : Audio File will be saved in your files you can download it from there"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
